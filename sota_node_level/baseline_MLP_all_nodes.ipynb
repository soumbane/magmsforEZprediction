{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Model for Node-Level classification - for left and right temporal lobe nodes\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat\n",
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.svm import SVC as SVM\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier as xgb\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_pred, y_true):\n",
    "\n",
    "    # conf_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # print('Confusion Matrix : \\n', conf_mat)\n",
    "\n",
    "    # total1=sum(sum(conf_mat))\n",
    "    \n",
    "    # accuracy1=(conf_mat[0,0]+conf_mat[1,1])/total1\n",
    "    # # print('Accuracy : ', accuracy1)\n",
    "\n",
    "    # sensitivity1 = conf_mat[0,0]/(conf_mat[0,0]+conf_mat[0,1])\n",
    "    # # print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "    # specificity1 = conf_mat[1,1]/(conf_mat[1,0]+conf_mat[1,1])\n",
    "    # # print('Specificity : ', specificity1)\n",
    "\n",
    "    bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    # print(f'Balanced Accuracy: {bal_acc:.4f}')\n",
    "\n",
    "    return bal_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root Folder\n",
    "root='/home/neil/Lab_work/Jeong_Lab_Multi_Modal_MRI/Right_Temporal_Lobe/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(root: str, node_num: str):\n",
    "\n",
    "    train_path = os.path.join(root, 'Node_'+node_num, 'Aug_Train_Data', 'ALL_Patients')  \n",
    "    x_file = f\"X_train_aug\"\n",
    "    y_file = f\"Y_train_aug\"\n",
    "    x_mat_name = \"X_aug_train\"\n",
    "    y_mat_name = \"Y_aug_train\"  \n",
    "\n",
    "    raw_path_x = os.path.join(train_path, f\"{x_file}.mat\")\n",
    "    raw_path_y = os.path.join(train_path, f\"{y_file}.mat\")\n",
    "\n",
    "    # Load the data from .mat files\n",
    "    X_mat_l = loadmat(raw_path_x)\n",
    "    X_mat = X_mat_l[x_mat_name]\n",
    "\n",
    "    Y_mat_l = loadmat(raw_path_y)\n",
    "    Y_mat = Y_mat_l[y_mat_name]\n",
    "    Y_mat = Y_mat.reshape(Y_mat.shape[1],)\n",
    "\n",
    "    X_multi_modal = X_mat\n",
    "    Y_label = Y_mat\n",
    "\n",
    "    # Load the 1D vectors (images) and binary labels\n",
    "    X_multi_modal: torch.Tensor = torch.from_numpy(X_multi_modal) \n",
    "    Y_label: torch.Tensor = torch.from_numpy(Y_label) # for CrossEntropyLoss\n",
    "    Y_label = Y_label.squeeze(dim=0).long()\n",
    "    X_multi_modal = X_multi_modal\n",
    "    X_multi_modal = X_multi_modal.squeeze(dim=0)\n",
    "\n",
    "    return X_multi_modal, Y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(root: str, node_num: str):\n",
    "\n",
    "    val_path = os.path.join(root, 'Node_'+node_num, 'Orig_Val_Data', 'ALL_Patients')  \n",
    "    x_file = f\"X_valid_orig\"\n",
    "    y_file = f\"Y_valid_orig\"\n",
    "    x_mat_name = \"X_orig_valid\"\n",
    "    y_mat_name = \"Y_orig_valid\"  \n",
    "\n",
    "    raw_path_x = os.path.join(val_path, f\"{x_file}.mat\")\n",
    "    raw_path_y = os.path.join(val_path, f\"{y_file}.mat\")\n",
    "\n",
    "    # Load the data from .mat files\n",
    "    X_mat_l = loadmat(raw_path_x)\n",
    "    X_mat = X_mat_l[x_mat_name]\n",
    "\n",
    "    Y_mat_l = loadmat(raw_path_y)\n",
    "    Y_mat = Y_mat_l[y_mat_name]\n",
    "    Y_mat = Y_mat.reshape(Y_mat.shape[1],)\n",
    "\n",
    "    X_multi_modal = X_mat\n",
    "    Y_label = Y_mat\n",
    "\n",
    "    # Load the 1D vectors (images) and binary labels\n",
    "    X_multi_modal: torch.Tensor = torch.from_numpy(X_multi_modal) \n",
    "    Y_label: torch.Tensor = torch.from_numpy(Y_label) # for CrossEntropyLoss\n",
    "    Y_label = Y_label.squeeze(dim=0).long()\n",
    "    X_multi_modal = X_multi_modal\n",
    "    X_multi_modal = X_multi_modal.squeeze(dim=0)\n",
    "\n",
    "    return X_multi_modal, Y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and testing/validation dataloaders\n",
    "def load_train_loader(X_train, Y_train):\n",
    "   train_data = []\n",
    "   for i in range(len(X_train)):\n",
    "      train_data.append([X_train[i], Y_train[i]])\n",
    "\n",
    "   train_loader = DataLoader(train_data, shuffle=True, drop_last=False, batch_size=4)  # type:ignore\n",
    "   return train_loader\n",
    "\n",
    "def load_test_loader(X_test, Y_test):\n",
    "   test_data = []\n",
    "   for i in range(len(X_test)):\n",
    "      test_data.append([X_test[i], Y_test[i]])\n",
    "   test_loader = DataLoader(test_data, shuffle=False, drop_last=False, batch_size=4)  # type:ignore\n",
    "   return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class MLP_ms(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Linear(1899, 512),\n",
    "      nn.Dropout(p=0.2),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(512, 512),\n",
    "      nn.Dropout(p=0.2),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "\n",
    "    self.layers_combined = nn.Sequential(\n",
    "      nn.Linear(512, 2)  # for CrossEntropyLoss\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x_out = self.layers(x)\n",
    "\n",
    "    x_final = self.layers_combined(x_out)\n",
    "\n",
    "    return x_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, optimizer, loss_fn, device=None):    \n",
    "    # Enumerate over the data\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "    step = 0\n",
    "\n",
    "    for _, (x,y) in enumerate(tqdm(train_loader)):\n",
    "        \n",
    "        # Use GPU\n",
    "        x.to(device) \n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Passing the node features and the connection info        \n",
    "        pred = model(x)   \n",
    "            \n",
    "        # Calculating the loss and gradients\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        loss.backward() \n",
    "\n",
    "        optimizer.step() \n",
    "\n",
    "        # Update tracking\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        step += 1\n",
    "\n",
    "        all_preds.append((pred.argmax(dim=-1)).cpu().detach().numpy()) # for CrossEntropyLoss\n",
    "        all_labels.append(y.cpu().detach().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "\n",
    "    return running_loss/step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, loss_fn, device=None):\n",
    "    all_preds = []\n",
    "    preds_for_auc = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "    step = 0\n",
    "\n",
    "    for (x,y) in test_loader:\n",
    "\n",
    "        x.to(device) \n",
    "\n",
    "        pred = model(x) \n",
    "\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Update tracking\n",
    "        running_loss += loss.item()\n",
    "        step += 1\n",
    "\n",
    "        all_preds.append((pred.argmax(dim=-1)).cpu().detach().numpy())  # for CrossEntropyLoss\n",
    "        all_labels.append(y.cpu().detach().numpy())\n",
    "    \n",
    "    all_preds = np.concatenate(all_preds).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "\n",
    "    bal_acc = calculate_metrics(all_preds, all_labels)\n",
    "\n",
    "    return running_loss/step, bal_acc, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all_epochs_per_node(model, train_loader, test_loader, epochs=100, patience=10, \n",
    "save_dir='', exp_id='', loss_fn=None, optimizer=None, device=None):\n",
    "    # Start training\n",
    "    best_loss = float('inf')\n",
    "    best_bal_acc = 0.0\n",
    "    early_stopping_counter = 0\n",
    "    best_epoch = 1\n",
    "    all_best_epoch_nums = []\n",
    "\n",
    "    for epoch in range(1, epochs+1): \n",
    "        if early_stopping_counter <= patience:\n",
    "\n",
    "            # Training\n",
    "            model.train()\n",
    "            loss = train_one_epoch(model, train_loader, optimizer, loss_fn, device=device)\n",
    "            print(f\"Epoch {epoch} | Train Loss {loss:.4f}\")\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "\n",
    "            loss, bal_acc, _, _ = test(model, test_loader, loss_fn, device=device)\n",
    "            print(f\"Epoch {epoch} | Test Loss {loss:.4f} | Bal. Acc. {bal_acc:.4f}\")\n",
    "\n",
    "            # Update best (highest) Balanced Accuracy\n",
    "            if float(bal_acc) > best_bal_acc:\n",
    "\n",
    "                print(f'Validation Balanced Accuracy increases from {best_bal_acc:.4f} to {bal_acc:.4f}')\n",
    "\n",
    "                best_bal_acc = bal_acc\n",
    "                \n",
    "                print('Saving best model with highest Balanced Accuracy ...')\n",
    "                best_model_wts = model.state_dict()\n",
    "                torch.save(best_model_wts, save_dir + \"exp_node_\" + str(exp_id) + \"_best_model.pth\")\n",
    "                best_epoch = epoch\n",
    "                all_best_epoch_nums.append(epoch)\n",
    "\n",
    "                early_stopping_counter = 0\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "\n",
    "        else:\n",
    "            print(\"Early stopping due to no improvement.\")\n",
    "        \n",
    "            print(f\"Finishing training with highest Balanced Accuracy: {best_bal_acc}\")\n",
    "            break\n",
    "\n",
    "\n",
    "    # Final Test with trained model\n",
    "    print('\\nTesting with the best model with highest Balanced Accuracy on test set ...\\n')\n",
    "    model.load_state_dict(torch.load(save_dir + \"exp_node_\" + str(exp_id) + \"_best_model.pth\"))\n",
    "\n",
    "    loss, bal_acc, y_pred, y_true = test(model, test_loader, loss_fn)\n",
    "\n",
    "    print(\"Printing Test Set Evaluation Metrics ....\\n\")\n",
    "    print(f\"Bal. Acc. {bal_acc:.4f}\")\n",
    "\n",
    "    print(f\"\\nBest scores occur at {best_epoch} epoch number\")\n",
    "\n",
    "    return bal_acc, y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_node_nums():\n",
    "    node_numbers_with_smote = [\n",
    "        \"948\"\n",
    "    ]\n",
    "\n",
    "    return node_numbers_with_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"./checkpoints/\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node num as string: 948\n",
      "Training and Evaluating on Node number: 948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 23.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss 3.2640\n",
      "Epoch 1 | Test Loss 0.5920 | Bal. Acc. 0.5000\n",
      "Validation Balanced Accuracy increases from 0.0000 to 0.5000\n",
      "Saving best model with highest Balanced Accuracy ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 140.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss 0.8427\n",
      "Epoch 2 | Test Loss 0.6509 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 139.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss 0.7468\n",
      "Epoch 3 | Test Loss 0.7210 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 135.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss 0.7416\n",
      "Epoch 4 | Test Loss 0.5620 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 134.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss 0.7529\n",
      "Epoch 5 | Test Loss 0.6886 | Bal. Acc. 0.5952\n",
      "Validation Balanced Accuracy increases from 0.5000 to 0.5952\n",
      "Saving best model with highest Balanced Accuracy ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 130.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss 0.7366\n",
      "Epoch 6 | Test Loss 0.7059 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 138.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss 0.7151\n",
      "Epoch 7 | Test Loss 0.8566 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 138.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss 0.8345\n",
      "Epoch 8 | Test Loss 0.6046 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 130.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss 0.7393\n",
      "Epoch 9 | Test Loss 0.6719 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 137.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss 0.7277\n",
      "Epoch 10 | Test Loss 0.6781 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 141.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss 0.7286\n",
      "Epoch 11 | Test Loss 0.6585 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 142.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss 0.7080\n",
      "Epoch 12 | Test Loss 0.6769 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 120.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss 0.7542\n",
      "Epoch 13 | Test Loss 0.7024 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 120.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss 0.7323\n",
      "Epoch 14 | Test Loss 0.6818 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 131.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss 0.7074\n",
      "Epoch 15 | Test Loss 2.0010 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 143.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss 0.7454\n",
      "Epoch 16 | Test Loss 0.6524 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 105.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss 0.7310\n",
      "Epoch 17 | Test Loss 0.6852 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 105.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss 0.6988\n",
      "Epoch 18 | Test Loss 0.6789 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 138.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss 0.6975\n",
      "Epoch 19 | Test Loss 0.6961 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 136.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss 0.6960\n",
      "Epoch 20 | Test Loss 0.6876 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 143.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss 0.7033\n",
      "Epoch 21 | Test Loss 0.6829 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 139.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss 0.7185\n",
      "Epoch 22 | Test Loss 0.6262 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 125.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss 0.8177\n",
      "Epoch 23 | Test Loss 0.6857 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 128.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss 0.7321\n",
      "Epoch 24 | Test Loss 0.6755 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 149.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss 0.6955\n",
      "Epoch 25 | Test Loss 0.6778 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 138.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss 0.7791\n",
      "Epoch 26 | Test Loss 0.7006 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 134.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss 0.6982\n",
      "Epoch 27 | Test Loss 0.6702 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 129.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss 0.7253\n",
      "Epoch 28 | Test Loss 0.6885 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 128.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss 0.6993\n",
      "Epoch 29 | Test Loss 0.6968 | Bal. Acc. 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 140.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss 0.7167\n",
      "Epoch 30 | Test Loss 0.6986 | Bal. Acc. 0.5000\n",
      "\n",
      "Testing with the best model with highest Balanced Accuracy on test set ...\n",
      "\n",
      "Printing Test Set Evaluation Metrics ....\n",
      "\n",
      "Bal. Acc. 0.5952\n",
      "\n",
      "Best scores occur at 5 epoch number\n",
      "y-prediction: [0 0 0 1 1 0 0 0 0 0]\n",
      "y-true: [0 1 1 0 1 0 0 0 0 0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Stop here",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/neil/Lab_work/Jeong_Lab_Multi_Modal_MRI/magmsforEZprediction/baselines_node_level/baseline_MLP_all_nodes.ipynb Cell 13\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.30.0.255/home/neil/Lab_work/Jeong_Lab_Multi_Modal_MRI/magmsforEZprediction/baselines_node_level/baseline_MLP_all_nodes.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my-prediction: \u001b[39m\u001b[39m{\u001b[39;00my_pred\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.30.0.255/home/neil/Lab_work/Jeong_Lab_Multi_Modal_MRI/magmsforEZprediction/baselines_node_level/baseline_MLP_all_nodes.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my-true: \u001b[39m\u001b[39m{\u001b[39;00my_true\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B172.30.0.255/home/neil/Lab_work/Jeong_Lab_Multi_Modal_MRI/magmsforEZprediction/baselines_node_level/baseline_MLP_all_nodes.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mStop here\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.30.0.255/home/neil/Lab_work/Jeong_Lab_Multi_Modal_MRI/magmsforEZprediction/baselines_node_level/baseline_MLP_all_nodes.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m# for saving balanced accuracy and confusion matrix of nodes with SMOTE in a csv file\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.30.0.255/home/neil/Lab_work/Jeong_Lab_Multi_Modal_MRI/magmsforEZprediction/baselines_node_level/baseline_MLP_all_nodes.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m node_num_list\u001b[39m.\u001b[39mappend(node_num)\n",
      "\u001b[0;31mValueError\u001b[0m: Stop here"
     ]
    }
   ],
   "source": [
    "# Main loop to train and test the model over all the nodes\n",
    "total_nodes = 1\n",
    "\n",
    "# choose model\n",
    "model_name = 'MLP_ms'\n",
    "\n",
    "# Define the model\n",
    "if model_name == 'MLP_ms':\n",
    "    # Initialize the model\n",
    "    model = MLP_ms()\n",
    "    model.double()\n",
    "else:\n",
    "    raise NotImplementedError(\"Unknown Model.\")\n",
    "\n",
    "# Train and test the model with these settings\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')  # type: ignore\n",
    "\n",
    "epochs = 30\n",
    "patience = 30 # needed for early stopping\n",
    "\n",
    "# Define training loss function and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "count = 0\n",
    "\n",
    "node_num_list = [] # stores the node numbers for all nodes\n",
    "bal_acc_list = [] # stores the balanced accuracies for all nodes\n",
    "sen_list = [] # stores the sensitivity for all nodes\n",
    "spec_list = [] # stores the specificity for all nodes\n",
    "\n",
    "# list of all 94 nodes\n",
    "node_numbers_with_smote = get_list_of_node_nums()\n",
    "\n",
    "for node_num in node_numbers_with_smote:    \n",
    "\n",
    "    exp_id = node_num # Experiment ID\n",
    "\n",
    "    print(f'Node num as string: {node_num}')\n",
    "\n",
    "    # load the data for the given node\n",
    "    X_train, Y_train = load_train_data(root, node_num)\n",
    "    train_loader = load_train_loader(X_train, Y_train)\n",
    "\n",
    "    X_test, Y_test = load_test_data(root, node_num)\n",
    "    test_loader = load_test_loader(X_test, Y_test)\n",
    "\n",
    "    # Train the model\n",
    "    print(f'Training and Evaluating on Node number: {node_num}')           \n",
    "\n",
    "    # Evaluate Trained Model with evaluation metrics\n",
    "    bal_acc, y_pred, y_true = train_all_epochs_per_node(model, train_loader, test_loader, epochs=epochs, \n",
    "    patience=patience, save_dir=save_dir, exp_id=exp_id, loss_fn=loss_fn, optimizer=optimizer, device=device)\n",
    "\n",
    "    print(f\"y-prediction: {y_pred}\")\n",
    "    print(f\"y-true: {y_true}\")\n",
    "    raise ValueError(\"Stop here\")\n",
    "\n",
    "    # for saving balanced accuracy and confusion matrix of nodes with SMOTE in a csv file\n",
    "    node_num_list.append(node_num)\n",
    "    bal_acc_list.append(bal_acc)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magms_ez",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
