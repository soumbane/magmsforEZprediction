{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest (RF) for Node-Level classification - for left and right hemisphere nodes\n",
    "import os\n",
    "from typing import Any, Union\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat\n",
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.svm import SVC as SVM\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_pred, y_true):\n",
    "\n",
    "    return balanced_accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root Folder\n",
    "# root='/home/neil/Lab_work/Jeong_Lab_Multi_Modal_MRI/Left_Hemis/Part_2/'\n",
    "# root='/home/neil/Lab_work/Jeong_Lab_Multi_Modal_MRI/Right_Hemis/Part_2/'\n",
    "\n",
    "root='/media/user1/MyHDataStor41/Soumyanil_EZ_Pred_project/Data/All_Hemispheres/Right_Hemis/Part_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left/Right Hemis Nodes\n",
    "# def get_list_of_node_nums():\n",
    "#     node_numbers_with_smote = [\n",
    "#     \"504\", \"506\", \"508\", \"509\", \"510\", \"511\", \"512\", \"513\", \"514\", \"515\", \"516\", \"517\", \"518\", \"519\", \"520\", \"521\", \"522\", \"524\", \"525\", \"526\", \"529\", \"530\", \"534\", \"535\", \"536\", \"537\", \"538\", \"539\", \"540\", \"541\", \"542\", \"543\", \"546\", \"547\", \"548\", \"549\", \"551\", \"552\", \"553\", \"554\", \"555\", \"556\", \"557\", \"558\", \"559\", \"560\", \"561\", \"562\", \"563\", \"564\", \"565\", \"566\", \"567\", \"568\", \"569\", \"570\", \"571\", \"572\", \"573\", \"574\", \"575\", \"576\", \"581\", \"582\", \"584\", \"585\", \"586\", \"587\", \"588\", \"589\", \"590\", \"591\", \"592\", \"593\", \"594\", \"595\", \"596\", \"598\", \"599\", \"600\", \"601\", \"602\", \"603\", \"604\", \"605\", \"606\", \"607\", \"608\", \"609\", \"610\", \"612\", \"613\", \"614\", \"615\", \"616\", \"617\", \"618\", \"619\", \"620\", \"621\", \"622\", \"623\", \"624\", \"625\", \"627\", \"628\", \"629\", \"630\", \"632\", \"633\", \"634\", \"635\", \"636\", \"637\", \"638\", \"639\", \"640\", \"641\", \"642\", \"643\", \"644\", \"645\", \"646\", \"647\", \"648\", \"649\", \"650\", \"651\", \"652\", \"655\", \"656\", \"657\", \"658\", \"659\", \"660\", \"661\", \"662\", \"663\", \"664\", \"665\", \"666\", \"668\", \"669\", \"670\", \"671\", \"672\", \"673\", \"674\", \"675\", \"676\", \"677\", \"678\", \"681\", \"683\", \"685\", \"686\", \"690\", \"691\", \"692\", \"693\", \"694\", \"695\", \"696\", \"697\", \"698\", \"699\", \"700\", \"701\", \"702\", \"703\", \"704\", \"705\", \"706\", \"707\", \"708\", \"709\", \"710\", \"711\", \"712\", \"713\", \"714\", \"715\", \"716\", \"717\", \"718\", \"719\", \"720\", \"721\", \"722\", \"723\", \"724\", \"725\", \"726\", \"727\", \"728\", \"730\", \"731\", \"732\", \"733\", \"735\", \"736\", \"737\", \"738\", \"739\", \"740\", \"741\", \"742\", \"743\", \"744\", \"745\", \"746\", \"747\", \"748\", \"749\", \"750\", \"751\", \"756\", \"757\", \"758\", \"759\", \"760\", \"761\", \"762\", \"763\", \"764\", \"765\", \"766\", \"767\", \"770\", \"771\", \"776\", \"777\", \"778\", \"779\", \"780\", \"781\", \"782\", \"783\", \"784\", \"785\", \"786\", \"787\", \"788\", \"789\", \"790\", \"791\", \"792\", \"793\", \"795\", \"796\", \"797\", \"798\", \"799\", \"800\", \"801\", \"802\", \"803\", \"804\", \"805\", \"806\", \"808\", \"809\", \"810\", \"811\", \"812\", \"813\", \"816\", \"817\", \"818\", \"819\", \"820\", \"821\", \"822\", \"823\", \"824\", \"825\", \"826\", \"827\", \"828\", \"829\", \"830\", \"831\", \"832\", \"834\", \"835\", \"836\", \"837\", \"838\", \"839\", \"841\", \"842\", \"843\", \"844\", \"845\", \"846\", \"847\", \"848\", \"849\", \"850\", \"851\", \"852\", \"853\", \"854\", \"855\", \"856\", \"857\", \"858\", \"859\", \"860\", \"861\", \"862\", \"863\", \"864\", \"865\", \"866\", \"867\", \"868\", \"869\", \"870\", \"871\", \"872\", \"873\", \"874\", \"875\", \"877\", \"878\", \"879\", \"880\", \"881\", \"882\", \"883\", \"885\", \"886\", \"887\", \"888\", \"889\", \"890\", \"891\", \"892\", \"893\", \"894\", \"895\", \"896\", \"897\", \"898\", \"899\", \"900\", \"901\", \"902\", \"903\", \"904\", \"905\", \"906\", \"907\", \"908\", \"909\", \"910\", \"911\", \"912\", \"913\", \"914\", \"915\", \"916\", \"917\", \"918\", \"919\", \"920\", \"921\", \"922\", \"923\", \"924\", \"925\", \"926\", \"927\", \"928\", \"929\", \"930\", \"931\", \"932\", \"933\", \"934\", \"935\", \"937\", \"938\", \"939\", \"940\", \"941\", \"942\", \"943\", \"944\", \"945\", \"946\", \"947\", \"948\", \"949\", \"950\", \"951\", \"952\", \"953\", \"954\", \"955\", \"956\", \"957\", \"958\", \"960\", \"961\", \"962\", \"963\", \"964\", \"965\", \"968\", \"969\", \"970\", \"971\", \"973\", \"974\", \"975\", \"976\", \"977\", \"978\", \"979\", \"980\", \"981\", \"982\", \"983\"\n",
    "#     ]\n",
    "\n",
    "#     return node_numbers_with_smote\n",
    "\n",
    "\n",
    "\n",
    "def get_list_of_node_nums():\n",
    "    node_numbers_with_smote = [\n",
    "    \"504\", \"506\", \"508\", \"509\", \"510\"\n",
    "    ]\n",
    "\n",
    "    return node_numbers_with_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "right_hemis_nodes = get_list_of_node_nums()\n",
    "print(len(right_hemis_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modality(num: int, X: np.ndarray, fill_zeros: bool = False) -> np.ndarray:\n",
    "    if num == 1:\n",
    "        dict_mod = {4:\"DWIC\"}\n",
    "        list_mod = [0,0,0,0,1]\n",
    "        if fill_zeros:\n",
    "            X_modality = X[:, 1400:]\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))), axis=1)\n",
    "        else:\n",
    "            X_modality = X[:, 1400:]\n",
    "    elif num == 2:\n",
    "        dict_mod = {3:\"DWI\"}\n",
    "        list_mod = [0,0,0,1,0]\n",
    "        if fill_zeros:\n",
    "            X_modality = X[:, 700:1400]\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))), axis=1)\n",
    "        else:\n",
    "            X_modality = X[:, 700:1400]\n",
    "    elif num == 3:\n",
    "        dict_mod = {3:\"DWI\", 4:\"DWIC\"}\n",
    "        list_mod = [0,0,0,1,1]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, 700:1400], X[:, 1400:]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))), axis=1)\n",
    "        else:\n",
    "            X_modality = np.concatenate((X[:, 700:1400], X[:, 1400:]), axis=1)\n",
    "    elif num == 4:\n",
    "        dict_mod = {2:\"FLAIR\"}\n",
    "        list_mod = [0,0,1,0,0]\n",
    "        if fill_zeros:\n",
    "            X_modality = X[:, 500:700]\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))), axis=1)\n",
    "        else:\n",
    "            X_modality = X[:, 500:700]\n",
    "    elif num == 5:\n",
    "        dict_mod = {2:\"FLAIR\", 4:\"DWIC\"}\n",
    "        list_mod = [0,0,1,0,1]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, 500:700], X[:, 1400:]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))), axis=1)\n",
    "        else:\n",
    "            X_modality = np.concatenate((X[:, 500:700], X[:, 1400:]), axis=1)\n",
    "    elif num == 6:\n",
    "        dict_mod = {2:\"FLAIR\", 3:\"DWI\"}\n",
    "        list_mod = [0,0,1,1,0]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, 500:700], X[:, 700:1400]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))), axis=1)\n",
    "        else:\n",
    "            X_modality = np.concatenate((X[:, 500:700], X[:, 700:1400]), axis=1)\n",
    "    elif num == 7:\n",
    "        dict_mod = {2:\"FLAIR\", 3:\"DWI\", 4:\"DWIC\"}\n",
    "        list_mod = [0,0,1,1,1]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, 500:700], X[:, 700:]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))), axis=1)\n",
    "        else:\n",
    "            X_modality = np.concatenate((X[:, 500:700], X[:, 700:]), axis=1)\n",
    "    elif num == 8:\n",
    "        dict_mod = {1:\"T2\"}\n",
    "        list_mod = [0,1,0,0,0]\n",
    "        if fill_zeros:\n",
    "            X_modality = X[:, 300:500]\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))), axis=1)\n",
    "        else:\n",
    "            X_modality = X[:, 300:500]\n",
    "    elif num == 9:\n",
    "        dict_mod = {1:\"T2\", 4:\"DWIC\"}\n",
    "        list_mod = [0,1,0,0,1]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, 300:500], X[:, 1400:]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))), axis=1)\n",
    "        else:\n",
    "            X_modality = np.concatenate((X[:, 300:500], X[:, 1400:]), axis=1)\n",
    "    elif num == 10:\n",
    "        dict_mod = {1:\"T2\", 3:\"DWI\"}\n",
    "        list_mod = [0,1,0,1,0]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, 300:500], X[:, 700:1400]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))), axis=1)\n",
    "        else:\n",
    "            X_modality = np.concatenate((X[:, 300:500], X[:, 700:1400]), axis=1)\n",
    "    elif num == 11:\n",
    "        dict_mod = {1:\"T2\", 3:\"DWI\", 4:\"DWIC\"}\n",
    "        list_mod = [0,1,0,1,1]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, 300:500], X[:, 700:]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))), axis=1)\n",
    "        else:\n",
    "            X_modality = np.concatenate((X[:, 300:500], X[:, 700:]), axis=1)\n",
    "    elif num == 12:\n",
    "        dict_mod = {1:\"T2\", 2:\"FLAIR\"}\n",
    "        list_mod = [0,1,1,0,0]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, 300:500], X[:, 500:700]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))), axis=1)\n",
    "        else:\n",
    "            X_modality = np.concatenate((X[:, 300:500], X[:, 500:700]), axis=1)\n",
    "    elif num == 13:\n",
    "        dict_mod = {1:\"T2\", 2:\"FLAIR\", 4:\"DWIC\"}\n",
    "        list_mod = [0,1,1,0,1]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, 300:500], X[:, 500:700], X[:, 1400:]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))), axis=1) \n",
    "        else:\n",
    "            X_modality = np.concatenate((X[:, 300:500], X[:, 500:700], X[:, 1400:]), axis=1)\n",
    "    elif num == 14:\n",
    "        dict_mod = {1:\"T2\", 2:\"FLAIR\", 3:\"DWI\"}\n",
    "        list_mod = [0,1,1,1,0]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, 300:500], X[:, 500:700], X[:, 700:1400]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))), axis=1) \n",
    "        else:\n",
    "            X_modality = np.concatenate((X[:, 300:500], X[:, 500:700], X[:, 700:1400]), axis=1)\n",
    "    elif num == 15:\n",
    "        dict_mod = {1:\"T2\", 2:\"FLAIR\", 3:\"DWI\", 4:\"DWIC\"}\n",
    "        list_mod = [0,1,1,1,1]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, 300:500], X[:, 500:700], X[:, 700:]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))), axis=1) \n",
    "        else:\n",
    "            X_modality = np.concatenate((X[:, 300:500], X[:, 500:700], X[:, 700:]), axis=1)\n",
    "    elif num == 16:\n",
    "        dict_mod = {0:\"T1\"}\n",
    "        list_mod = [1,0,0,0,0]\n",
    "        if fill_zeros:\n",
    "            X_modality = X[:, :300]\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))), axis=1)\n",
    "        else:\n",
    "            X_modality = X[:, :300]\n",
    "    elif num == 17:\n",
    "        dict_mod = {0:\"T1\", 4:\"DWIC\"}\n",
    "        list_mod = [1,0,0,0,1]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 1400:]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))), axis=1)\n",
    "        else:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 1400:]), axis=1)\n",
    "    elif num == 18:\n",
    "        dict_mod = {0:\"T1\", 3:\"DWI\"}\n",
    "        list_mod = [1,0,0,1,0]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 700:1400]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))), axis=1)\n",
    "        else:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 700:1400]), axis=1)\n",
    "    elif num == 19:\n",
    "        dict_mod = {0:\"T1\", 3:\"DWI\", 4:\"DWIC\"}\n",
    "        list_mod = [1,0,0,1,1]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 700:]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))), axis=1)\n",
    "        else:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 700:]), axis=1)\n",
    "    elif num == 20:\n",
    "        dict_mod = {0:\"T1\", 2:\"FLAIR\"}\n",
    "        list_mod = [1,0,1,0,0]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 500:700]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))), axis=1)\n",
    "        else:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 500:700]), axis=1)\n",
    "    elif num == 21:\n",
    "        dict_mod = {0:\"T1\", 2:\"FLAIR\", 4:\"DWIC\"}\n",
    "        list_mod = [1,0,1,0,1]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 500:700], X[:, 1400:]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))), axis=1)\n",
    "        else:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 500:700], X[:, 1400:]), axis=1)\n",
    "    elif num == 22:\n",
    "        dict_mod = {0:\"T1\", 2:\"FLAIR\", 3:\"DWI\"}\n",
    "        list_mod = [1,0,1,1,0]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 500:700], X[:, 700:1400]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))), axis=1)\n",
    "        else:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 500:700], X[:, 700:1400]), axis=1)\n",
    "    elif num == 23:\n",
    "        dict_mod = {0:\"T1\", 2:\"FLAIR\", 3:\"DWI\", 4:\"DWIC\"}\n",
    "        list_mod = [1,0,1,1,1]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 500:700], X[:, 700:]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))),axis=1)\n",
    "        else:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 500:700], X[:, 700:]), axis=1)\n",
    "    elif num == 24:\n",
    "        dict_mod = {0:\"T1\", 1:\"T2\"}\n",
    "        list_mod = [1,1,0,0,0]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 300:500]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))),axis=1)\n",
    "        else:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 300:500]), axis=1)\n",
    "    elif num == 25:\n",
    "        dict_mod = {0:\"T1\", 1:\"T2\", 4:\"DWIC\"}\n",
    "        list_mod = [1,1,0,0,1]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 300:500], X[:, 1400:]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))),axis=1)\n",
    "        else:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 300:500], X[:, 1400:]), axis=1)\n",
    "    elif num == 26:\n",
    "        dict_mod = {0:\"T1\", 1:\"T2\", 3:\"DWI\"}\n",
    "        list_mod = [1,1,0,1,0]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 300:500], X[:, 700:1400]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))),axis=1)\n",
    "        else:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 300:500], X[:, 700:1400]), axis=1)\n",
    "    elif num == 27:\n",
    "        dict_mod = {0:\"T1\", 1:\"T2\", 3:\"DWI\", 4:\"DWIC\"}\n",
    "        list_mod = [1,1,0,1,1]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 300:500], X[:, 700:]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))),axis=1)\n",
    "        else:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 300:500], X[:, 700:]), axis=1)\n",
    "    elif num == 28:\n",
    "        dict_mod = {0:\"T1\", 1:\"T2\", 2:\"FLAIR\"}\n",
    "        list_mod = [1,1,1,0,0]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 300:500], X[:, 500:700]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))),axis=1)\n",
    "        else:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 300:500], X[:, 500:700]), axis=1)\n",
    "    elif num == 29:\n",
    "        dict_mod = {0:\"T1\", 1:\"T2\", 2:\"FLAIR\", 4:\"DWIC\"}\n",
    "        list_mod = [1,1,1,0,1]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 300:500], X[:, 500:700], X[:, 1400:]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))),axis=1)\n",
    "        else:        \n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 300:500], X[:, 500:700], X[:, 1400:]), axis=1)\n",
    "    elif num == 30:\n",
    "        dict_mod = {0:\"T1\", 1:\"T2\", 2:\"FLAIR\", 3:\"DWI\"}\n",
    "        list_mod = [1,1,1,1,0]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 300:500], X[:, 500:700], X[:, 700:1400]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))),axis=1)\n",
    "        else:        \n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 300:500], X[:, 500:700], X[:, 700:1400]), axis=1)\n",
    "    elif num == 31:\n",
    "        dict_mod = {0:\"T1\", 1:\"T2\", 2:\"FLAIR\", 3:\"DWI\", 4:\"DWIC\"}\n",
    "        list_mod = [1,1,1,1,1]\n",
    "        if fill_zeros:\n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 300:500], X[:, 500:700], X[:, 700:]), axis=1)\n",
    "            X_modality = np.concatenate((X_modality, np.zeros((X.shape[0], (X.shape[1]-X_modality.shape[1])))),axis=1)\n",
    "        else:        \n",
    "            X_modality = np.concatenate((X[:, :300], X[:, 300:500], X[:, 500:700], X[:, 700:]), axis=1)\n",
    "    else:\n",
    "        raise ValueError(f\"num should be betwen 1 and 31, got {num}\")\n",
    "\n",
    "    return X_modality, dict_mod # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(root: str, node_num: str, j: int):\n",
    "\n",
    "    train_path = os.path.join(root, 'Node_'+node_num, 'Aug_Train_Data', 'ALL_Patients')  \n",
    "    x_file = f\"X_train_aug\"\n",
    "    y_file = f\"Y_train_aug\"\n",
    "    x_mat_name = \"X_aug_train\"\n",
    "    y_mat_name = \"Y_aug_train\"  \n",
    "\n",
    "    raw_path_x = os.path.join(train_path, f\"{x_file}.mat\")\n",
    "    raw_path_y = os.path.join(train_path, f\"{y_file}.mat\")\n",
    "\n",
    "    # Load the data from .mat files\n",
    "    X_mat_l = loadmat(raw_path_x)\n",
    "    X_mat = X_mat_l[x_mat_name]\n",
    "\n",
    "    X_mat_modality, dict_mod = get_modality(j, X_mat) # get X for the modality\n",
    "\n",
    "    Y_mat_l = loadmat(raw_path_y)\n",
    "    Y_mat = Y_mat_l[y_mat_name]\n",
    "    Y_mat = Y_mat.reshape(Y_mat.shape[1],)\n",
    "\n",
    "    # # Count and print the number of 0s and 1s\n",
    "    # num_zeros = np.sum(Y_mat == 0)\n",
    "    # num_ones = np.sum(Y_mat == 1)\n",
    "    # print(f\"Train data for Node {node_num}, Modality {j}: Class 0 count = {num_zeros}, Class 1 count = {num_ones}\")\n",
    "\n",
    "    return X_mat_modality, Y_mat, dict_mod\n",
    "    # return X_mat, Y_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(root: str, node_num: str, j: int):\n",
    "\n",
    "    val_path = os.path.join(root, 'Node_'+node_num, 'Orig_Val_Data', 'ALL_Patients')  \n",
    "    x_file = f\"X_valid_orig\"\n",
    "    y_file = f\"Y_valid_orig\"\n",
    "    x_mat_name = \"X_orig_valid\"\n",
    "    y_mat_name = \"Y_orig_valid\"  \n",
    "\n",
    "    raw_path_x = os.path.join(val_path, f\"{x_file}.mat\")\n",
    "    raw_path_y = os.path.join(val_path, f\"{y_file}.mat\")\n",
    "\n",
    "    # Load the data from .mat files\n",
    "    X_mat_l = loadmat(raw_path_x)\n",
    "    X_mat = X_mat_l[x_mat_name]\n",
    "\n",
    "    X_mat_modality, dict_mod = get_modality(j, X_mat) # get X for the modality\n",
    "    # X_mat_modality, dict_mod = get_modality(j, X_mat, fill_zeros=True) # get X for the modality\n",
    "\n",
    "    Y_mat_l = loadmat(raw_path_y)\n",
    "    Y_mat = Y_mat_l[y_mat_name]\n",
    "    Y_mat = Y_mat.reshape(Y_mat.shape[1],)\n",
    "\n",
    "    # # Count and print the number of 0s and 1s\n",
    "    # num_zeros = np.sum(Y_mat == 0)\n",
    "    # num_ones = np.sum(Y_mat == 1)\n",
    "    # print(f\"Test data for Node {node_num}, Modality {j}: Class 0 count = {num_zeros}, Class 1 count = {num_ones}\")\n",
    "\n",
    "    return X_mat_modality, Y_mat, dict_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class MRIModalityBranch(nn.Module):\n",
    "    \"\"\"\n",
    "    1D CNN branch for each MRI modality with adaptive architecture based on input size\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, dropout_rate=0.5):\n",
    "        super(MRIModalityBranch, self).__init__()\n",
    "        \n",
    "        # Determine the number of conv layers based on input size\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        # First conv block\n",
    "        self.layers.append(nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.MaxPool1d(2)\n",
    "        ))\n",
    "        \n",
    "        # Track size after each layer\n",
    "        current_size = input_size // 2\n",
    "        \n",
    "        # Second conv block\n",
    "        if current_size > 50:\n",
    "            self.layers.append(nn.Sequential(\n",
    "                nn.Conv1d(16, 32, kernel_size=3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(32),\n",
    "                nn.MaxPool1d(2)\n",
    "            ))\n",
    "            current_size = current_size // 2\n",
    "        \n",
    "        # Dropout\n",
    "        self.layers.append(nn.Dropout(dropout_rate))\n",
    "        \n",
    "        # Third conv block\n",
    "        if current_size > 25:\n",
    "            self.layers.append(nn.Sequential(\n",
    "                nn.Conv1d(32, 64, kernel_size=3, padding=1),\n",
    "                nn.MaxPool1d(2)\n",
    "            ))\n",
    "            current_size = current_size // 2\n",
    "            self.final_channels = 64\n",
    "        else:\n",
    "            self.final_channels = 32\n",
    "        \n",
    "        # Calculate the output feature size\n",
    "        self.output_size = current_size * self.final_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, features)\n",
    "        x = x.unsqueeze(1)  # Add channel dimension: (batch_size, 1, features)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Flatten the output\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "class HierarchicalMRIModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Hierarchical 1D CNN model for multiple MRI modalities\n",
    "    \"\"\"\n",
    "    def __init__(self, modality_lengths, dropout_rate=0.5):\n",
    "        super(HierarchicalMRIModel, self).__init__()\n",
    "        \n",
    "        # Create a branch for each modality\n",
    "        self.branches = nn.ModuleDict()\n",
    "        self.modality_lengths = modality_lengths\n",
    "        \n",
    "        total_features = 0\n",
    "        for modality_name, length in modality_lengths.items():\n",
    "            if length > 0:\n",
    "                self.branches[modality_name] = MRIModalityBranch(length, dropout_rate)\n",
    "                total_features += self.branches[modality_name].output_size\n",
    "        \n",
    "        # MLP classifier after concatenation\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(total_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)  # Binary classification\n",
    "        )\n",
    "    \n",
    "    def forward(self, x_dict):\n",
    "        # Process each modality through its branch\n",
    "        features = []\n",
    "        for modality_name, branch in self.branches.items():\n",
    "            if self.modality_lengths[modality_name] > 0 and modality_name in x_dict:\n",
    "                features.append(branch(x_dict[modality_name]))\n",
    "        \n",
    "        # Concatenate all features\n",
    "        if len(features) > 0:\n",
    "            combined_features = torch.cat(features, dim=1)\n",
    "            \n",
    "            # Apply classifier\n",
    "            output = self.classifier(combined_features)\n",
    "            return output\n",
    "        else:\n",
    "            raise ValueError(\"No valid modalities provided\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modality_data(num, X):\n",
    "    \"\"\"\n",
    "    Extract data for specific modality combination\n",
    "    Returns a dictionary with individual modalities\n",
    "    \"\"\"\n",
    "    modality_dict = {}\n",
    "    modality_lengths = {\n",
    "        \"T1\": 0, \"T2\": 0, \"FLAIR\": 0, \"DWI\": 0, \"DWIC\": 0\n",
    "    }\n",
    "    \n",
    "    # Based on the existing get_modality function logic\n",
    "    if num & 1:  # T1\n",
    "        modality_dict[\"T1\"] = X[:, :300]\n",
    "        modality_lengths[\"T1\"] = 300\n",
    "    \n",
    "    if num & 2:  # T2\n",
    "        modality_dict[\"T2\"] = X[:, 300:500]\n",
    "        modality_lengths[\"T2\"] = 200\n",
    "    \n",
    "    if num & 4:  # FLAIR\n",
    "        modality_dict[\"FLAIR\"] = X[:, 500:700]\n",
    "        modality_lengths[\"FLAIR\"] = 200\n",
    "    \n",
    "    if num & 8:  # DWI\n",
    "        modality_dict[\"DWI\"] = X[:, 700:1400]\n",
    "        modality_lengths[\"DWI\"] = 700\n",
    "    \n",
    "    if num & 16:  # DWIC\n",
    "        modality_dict[\"DWIC\"] = X[:, 1400:]\n",
    "        modality_lengths[\"DWIC\"] = X.shape[1] - 1400\n",
    "    \n",
    "    return modality_dict, modality_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate the model's performance\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            # Extract batch data\n",
    "            x_dict = {modality: batch[i].to(device) for i, modality in enumerate(batch[:-1])}\n",
    "            y = batch[-1].numpy()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(x_dict)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            y_true_all.extend(y)\n",
    "            y_pred_all.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    bal_acc = calculate_metrics(y_pred_all, y_true_all)\n",
    "    return bal_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, device, epochs=30, patience=5):\n",
    "    \"\"\"\n",
    "    Train the model with early stopping\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    train_losses = []\n",
    "    val_accs = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            # Extract batch data\n",
    "            x_dict = {modality: batch[i].to(device) for i, modality in enumerate(batch[:-1])}\n",
    "            y = batch[-1].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_dict)\n",
    "            loss = criterion(outputs, y)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(avg_loss)\n",
    "        \n",
    "        # Validation\n",
    "        val_acc = evaluate(model, val_loader, device)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                model.load_state_dict(best_model_state)\n",
    "                break\n",
    "    \n",
    "    return model, train_losses, val_accs, best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_loaders(X_modality_dict, Y, batch_size=32):\n",
    "    \"\"\"\n",
    "    Prepare data loaders for model training\n",
    "    \"\"\"\n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    tensor_dict = {}\n",
    "    for modality, data in X_modality_dict.items():\n",
    "        tensor_dict[modality] = torch.FloatTensor(data)\n",
    "    \n",
    "    y_tensor = torch.LongTensor(Y)\n",
    "    \n",
    "    # Create a list of tensors in a fixed order + label\n",
    "    tensor_list = list(tensor_dict.values()) + [y_tensor]\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = TensorDataset(*tensor_list)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return data_loader, list(tensor_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "def main():\n",
    "    root='/media/user1/MyHDataStor41/Soumyanil_EZ_Pred_project/Data/All_Hemispheres/Right_Hemis/Part_2/'\n",
    "    node_numbers = get_list_of_node_nums()\n",
    "    \n",
    "    # Check for GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Results storage\n",
    "    results = []\n",
    "    \n",
    "    for node_num in node_numbers:\n",
    "        print(f'Processing Node: {node_num}')\n",
    "        \n",
    "        node_results = []\n",
    "        \n",
    "        # Train and test ALL modality combinations\n",
    "        for j in range(1, 32):\n",
    "            print(f'\\nModality Combination: {j}')\n",
    "            \n",
    "            # Load data\n",
    "            X_train_dict, modality_lengths, Y_train = load_train_data(root, node_num, j)\n",
    "            X_test_dict, _, Y_test = load_test_data(root, node_num, j)\n",
    "            \n",
    "            # Create data loaders\n",
    "            train_loader, modality_names = prepare_data_loaders(X_train_dict, Y_train)\n",
    "            test_loader, _ = prepare_data_loaders(X_test_dict, Y_test, batch_size=64)\n",
    "            \n",
    "            # Create model\n",
    "            model = HierarchicalMRIModel(modality_lengths).to(device)\n",
    "            print(f\"Model created with modalities: {list(X_train_dict.keys())}\")\n",
    "            \n",
    "            # Train model\n",
    "            model, train_losses, val_accs, best_val_acc = train_model(\n",
    "                model, train_loader, test_loader, device\n",
    "            )\n",
    "            \n",
    "            # Final evaluation\n",
    "            final_acc = evaluate(model, test_loader, device)\n",
    "            print(f\"Final balanced accuracy: {final_acc:.4f}\")\n",
    "            \n",
    "            # Store results\n",
    "            node_results.append({\n",
    "                'node': node_num,\n",
    "                'modality_combo': j,\n",
    "                'modalities': list(X_train_dict.keys()),\n",
    "                'accuracy': final_acc\n",
    "            })\n",
    "        \n",
    "        # Save node results\n",
    "        results.extend(node_results)\n",
    "        \n",
    "        # Create a DataFrame for this node\n",
    "        df_node = pd.DataFrame(\n",
    "            [r['accuracy'] for r in node_results], \n",
    "            columns=[f'Node_{node_num}']\n",
    "        )\n",
    "        \n",
    "        # Save to Excel\n",
    "        path = f\"/media/user1/MyHDataStor41/Soumyanil_EZ_Pred_project/magmsforEZprediction/hierarchical_cnn_results/\"\n",
    "        save_path = os.path.join(path, f\"Node_{node_num}\", \"Eval_Results\")\n",
    "        \n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "            \n",
    "        filename = \"hierarchical_cnn_results_val_ALL_modality_combination.xlsx\"\n",
    "        save_filepath = os.path.join(save_path, filename)\n",
    "        \n",
    "        df_node.to_excel(save_filepath, index=False, sheet_name='Sheet1')\n",
    "    \n",
    "    # Save combined results\n",
    "    df_all = pd.DataFrame(results)\n",
    "    df_all.to_excel(os.path.join(path, \"hierarchical_cnn_ALL_nodes_combined.xlsx\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node num: 504\n",
      "Train data for Node 504, Modality 1: Class 0 count = 60, Class 1 count = 60\n",
      "X_train shape: (120, 499)\n",
      "Test data for Node 504, Modality 1: Class 0 count = 10, Class 1 count = 0\n",
      "X_test shape: (10, 499)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Stop here",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m X_test, Y_test, dict_mod \u001b[38;5;241m=\u001b[39m load_test_data(root, node_num, j)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_test shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_test\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStop here\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModality Combination: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdict_mod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Define the model\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Stop here"
     ]
    }
   ],
   "source": [
    "# Main loop to run the baseline models over all the nodes (for all 3 trials)\n",
    "\n",
    "node_numbers_with_smote = get_list_of_node_nums()\n",
    "\n",
    "for node_num in node_numbers_with_smote:\n",
    "    \n",
    "    print(f'Node num: {node_num}')\n",
    "\n",
    "    num_trials = 3\n",
    "    \n",
    "    val_bal_acc_per_modality_list = []\n",
    "\n",
    "    # Train and test ALL modality combinations for ALL trials\n",
    "    for j in range(1,32): \n",
    "        # load the data for the given node and given modality combination\n",
    "        X_train, Y_train, dict_mod = load_train_data(root, node_num, j)\n",
    "        # X_train, Y_train = load_train_data(root, node_num, j)\n",
    "\n",
    "        # print(f\"X_train shape: {X_train.shape}\")\n",
    "        \n",
    "        X_test, Y_test, dict_mod = load_test_data(root, node_num, j)\n",
    "\n",
    "        # print(f\"X_test shape: {X_test.shape}\")\n",
    "        # raise ValueError(\"Stop here\")\n",
    "\n",
    "        print(f\"Modality Combination: {dict_mod}\")\n",
    "\n",
    "        # Define the model\n",
    "        if model == 'MLP':\n",
    "            clf = MLP(hidden_layer_sizes=(256,), learning_rate_init=0.01, random_state=None, max_iter=1000, early_stopping=False)\n",
    "        elif model == 'RF':\n",
    "            clf = RF(n_estimators=100, random_state=None,)\n",
    "        elif model == 'SVM':\n",
    "            clf = SVM(C=1.0, kernel='rbf', max_iter=-1, random_state=None)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Unknown Model.\")\n",
    "\n",
    "        val_bal_acc_list = []\n",
    "        # Run 5 trials for each node\n",
    "        for i in range(num_trials):\n",
    "            print(f'Training Trial {i+1} of Node number {node_num}')\n",
    "\n",
    "            # Train the model\n",
    "            clf.fit(X_train, Y_train)\n",
    "\n",
    "            # Test the model\n",
    "            print(f'Evaluating Trial {i+1} of Node number: {node_num}')\n",
    "            y_true = Y_test\n",
    "            y_pred = clf.predict(X_test)\n",
    "\n",
    "            # Evaluate Trained Model with evaluation metrics\n",
    "            bal_acc = calculate_metrics(y_pred, y_true)  \n",
    "            # print(f\"Balanced Accuracy: {bal_acc}\")\n",
    "\n",
    "            val_bal_acc_list.append(bal_acc) \n",
    "\n",
    "        val_bal_acc_per_modality_list.append(np.mean(val_bal_acc_list))\n",
    "\n",
    "    # Create a DataFrame\n",
    "    headers_val = ['Node_'+node_num]\n",
    "\n",
    "    df_val = pd.DataFrame(val_bal_acc_per_modality_list, columns=headers_val)\n",
    "\n",
    "    # Saving to Excel\n",
    "    # path = \"/home/neil/Lab_work/Jeong_Lab_Multi_Modal_MRI/magmsforEZprediction/baselines_node_level/\" \n",
    "    path = f\"/media/user1/MyHDataStor41/Soumyanil_EZ_Pred_project/magmsforEZprediction/sota_node_level/{model}_Results/\" \n",
    "    save_path = os.path.join(path, \"Node_\"+node_num, \"Eval_Results\")\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    filename_val = \"RF_results_val_ALL_modality_combination_test.xlsx\"\n",
    "    save_filepath_val = os.path.join(save_path, filename_val)\n",
    "\n",
    "    df_val.to_excel(save_filepath_val, index=False, sheet_name='Sheet1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all node results into one dataframe\n",
    "\n",
    "# Define the paths of your Excel files\n",
    "base_path = \"/home/neil/Lab_work/Jeong_Lab_Multi_Modal_MRI/magmsforEZprediction/baselines_node_level/\" \n",
    "\n",
    "# For FULL modality Only\n",
    "node_nums = get_list_of_node_nums()\n",
    "\n",
    "file_paths_val = []\n",
    "\n",
    "for node_num in node_nums:\n",
    "    file_path_val = os.path.join(base_path, \"Node_\"+node_num+\"_Results\", \"Eval_Results\", \"RF_results_val_ALL_modality_combination_test.xlsx\") # For FULL modality Only\n",
    "    file_paths_val.append(file_path_val)\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "combined_df_val = pd.DataFrame()\n",
    "\n",
    "# Loop through the files and stack the rows\n",
    "for path in file_paths_val:\n",
    "    # Load the Excel file\n",
    "    df = pd.read_excel(path)  \n",
    "\n",
    "    # Stack the rows\n",
    "    combined_df_val = pd.concat([combined_df_val, df], axis=1) # For ALL modality combinations\n",
    "\n",
    "# Reset the index to avoid duplicate row indices\n",
    "combined_df_val = combined_df_val.reset_index(drop=True)\n",
    "\n",
    "# Save the combined DataFrame to a new Excel file\n",
    "# combined_df_val.to_excel('RF_results_val_ALL_modality_combination_combined_Right_Hemis.xlsx', index=False)\n",
    "combined_df_val.to_excel('RF_results_val_ALL_modality_combination_combined_Right_Hemis_test.xlsx', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magms_ez",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
