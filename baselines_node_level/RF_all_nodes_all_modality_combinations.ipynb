{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest (RF) for Node-Level classification - for left and right hemisphere nodes\n",
    "import os\n",
    "from typing import Any, Union\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat\n",
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.svm import SVC as SVM\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_pred, y_true):\n",
    "\n",
    "    return balanced_accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root Folder\n",
    "# root='/home/neil/Lab_work/Jeong_Lab_Multi_Modal_MRI/Left_Hemis/Part_2/'\n",
    "root='/home/neil/Lab_work/Jeong_Lab_Multi_Modal_MRI/Right_Hemis/Part_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right Hemis Nodes\n",
    "def get_list_of_node_nums():\n",
    "    node_numbers_with_smote = [\n",
    "    \"513\"\n",
    "    ]\n",
    "\n",
    "    return node_numbers_with_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "right_hemis_nodes = get_list_of_node_nums()\n",
    "print(len(right_hemis_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modality(num: int, X: np.ndarray) -> np.ndarray:\n",
    "    if num == 1:\n",
    "        dict_mod = {4:\"DWIC\"}\n",
    "        list_mod = [0,0,0,0,1]\n",
    "        X_modality = X[:, 1400:]\n",
    "    elif num == 2:\n",
    "        dict_mod = {3:\"DWI\"}\n",
    "        list_mod = [0,0,0,1,0]\n",
    "        X_modality = X[:, 700:1400]\n",
    "    elif num == 3:\n",
    "        dict_mod = {3:\"DWI\", 4:\"DWIC\"}\n",
    "        list_mod = [0,0,0,1,1]\n",
    "        X_modality = np.concatenate((X[:, 700:1400], X[:, 1400:]), axis=1)\n",
    "    elif num == 4:\n",
    "        dict_mod = {2:\"FLAIR\"}\n",
    "        list_mod = [0,0,1,0,0]\n",
    "        X_modality = X[:, 500:700]\n",
    "    elif num == 5:\n",
    "        dict_mod = {2:\"FLAIR\", 4:\"DWIC\"}\n",
    "        list_mod = [0,0,1,0,1]\n",
    "        X_modality = np.concatenate((X[:, 500:700], X[:, 1400:]), axis=1)\n",
    "    elif num == 6:\n",
    "        dict_mod = {2:\"FLAIR\", 3:\"DWI\"}\n",
    "        list_mod = [0,0,1,1,0]\n",
    "        X_modality = np.concatenate((X[:, 500:700], X[:, 700:1400]), axis=1)\n",
    "    elif num == 7:\n",
    "        dict_mod = {2:\"FLAIR\", 3:\"DWI\", 4:\"DWIC\"}\n",
    "        list_mod = [0,0,1,1,1]\n",
    "        X_modality = np.concatenate((X[:, 500:700], X[:, 700:]), axis=1)\n",
    "    elif num == 8:\n",
    "        dict_mod = {1:\"T2\"}\n",
    "        list_mod = [0,1,0,0,0]\n",
    "        X_modality = X[:, 300:500]\n",
    "    elif num == 9:\n",
    "        dict_mod = {1:\"T2\", 4:\"DWIC\"}\n",
    "        list_mod = [0,1,0,0,1]\n",
    "        X_modality = np.concatenate((X[:, 300:500], X[:, 1400:]), axis=1)\n",
    "    elif num == 10:\n",
    "        dict_mod = {1:\"T2\", 3:\"DWI\"}\n",
    "        list_mod = [0,1,0,1,0]\n",
    "        X_modality = np.concatenate((X[:, 300:500], X[:, 700:1400]), axis=1)\n",
    "    elif num == 11:\n",
    "        dict_mod = {1:\"T2\", 3:\"DWI\", 4:\"DWIC\"}\n",
    "        list_mod = [0,1,0,1,1]\n",
    "        X_modality = np.concatenate((X[:, 300:500], X[:, 700:]), axis=1)\n",
    "    elif num == 12:\n",
    "        dict_mod = {1:\"T2\", 2:\"FLAIR\"}\n",
    "        list_mod = [0,1,1,0,0]\n",
    "        X_modality = np.concatenate((X[:, 300:500], X[:, 500:700]), axis=1)\n",
    "    elif num == 13:\n",
    "        dict_mod = {1:\"T2\", 2:\"FLAIR\", 4:\"DWIC\"}\n",
    "        list_mod = [0,1,1,0,1]\n",
    "        X_modality = np.concatenate((X[:, 300:500], X[:, 500:700], X[:, 1400:]), axis=1)\n",
    "    elif num == 14:\n",
    "        dict_mod = {1:\"T2\", 2:\"FLAIR\", 3:\"DWI\"}\n",
    "        list_mod = [0,1,1,1,0]\n",
    "        X_modality = np.concatenate((X[:, 300:500], X[:, 500:700], X[:, 700:1400]), axis=1)\n",
    "    elif num == 15:\n",
    "        dict_mod = {1:\"T2\", 2:\"FLAIR\", 3:\"DWI\", 4:\"DWIC\"}\n",
    "        list_mod = [0,1,1,1,1]\n",
    "        X_modality = np.concatenate((X[:, 300:500], X[:, 500:700], X[:, 700:]), axis=1)\n",
    "    elif num == 16:\n",
    "        dict_mod = {0:\"T1\"}\n",
    "        list_mod = [1,0,0,0,0]\n",
    "        X_modality = X[:, :300]\n",
    "    elif num == 17:\n",
    "        dict_mod = {0:\"T1\", 4:\"DWIC\"}\n",
    "        list_mod = [1,0,0,0,1]\n",
    "        X_modality = np.concatenate((X[:, :300], X[:, 1400:]), axis=1)\n",
    "    elif num == 18:\n",
    "        dict_mod = {0:\"T1\", 3:\"DWI\"}\n",
    "        list_mod = [1,0,0,1,0]\n",
    "        X_modality = np.concatenate((X[:, :300], X[:, 700:1400]), axis=1)\n",
    "    elif num == 19:\n",
    "        dict_mod = {0:\"T1\", 3:\"DWI\", 4:\"DWIC\"}\n",
    "        list_mod = [1,0,0,1,1]\n",
    "        X_modality = np.concatenate((X[:, :300], X[:, 700:]), axis=1)\n",
    "    elif num == 20:\n",
    "        dict_mod = {0:\"T1\", 2:\"FLAIR\"}\n",
    "        list_mod = [1,0,1,0,0]\n",
    "        X_modality = np.concatenate((X[:, :300], X[:, 500:700]), axis=1)\n",
    "    elif num == 21:\n",
    "        dict_mod = {0:\"T1\", 2:\"FLAIR\", 4:\"DWIC\"}\n",
    "        list_mod = [1,0,1,0,1]\n",
    "        X_modality = np.concatenate((X[:, :300], X[:, 500:700], X[:, 1400:]), axis=1)\n",
    "    elif num == 22:\n",
    "        dict_mod = {0:\"T1\", 2:\"FLAIR\", 3:\"DWI\"}\n",
    "        list_mod = [1,0,1,1,0]\n",
    "        X_modality = np.concatenate((X[:, :300], X[:, 500:700], X[:, 700:1400]), axis=1)\n",
    "    elif num == 23:\n",
    "        dict_mod = {0:\"T1\", 2:\"FLAIR\", 3:\"DWI\", 4:\"DWIC\"}\n",
    "        list_mod = [1,0,1,1,1]\n",
    "        X_modality = np.concatenate((X[:, :300], X[:, 500:700], X[:, 700:]), axis=1)\n",
    "    elif num == 24:\n",
    "        dict_mod = {0:\"T1\", 1:\"T2\"}\n",
    "        list_mod = [1,1,0,0,0]\n",
    "        X_modality = np.concatenate((X[:, :300], X[:, 300:500]), axis=1)\n",
    "    elif num == 25:\n",
    "        dict_mod = {0:\"T1\", 1:\"T2\", 4:\"DWIC\"}\n",
    "        list_mod = [1,1,0,0,1]\n",
    "        X_modality = np.concatenate((X[:, :300], X[:, 300:500], X[:, 1400:]), axis=1)\n",
    "    elif num == 26:\n",
    "        dict_mod = {0:\"T1\", 1:\"T2\", 3:\"DWI\"}\n",
    "        list_mod = [1,1,0,1,0]\n",
    "        X_modality = np.concatenate((X[:, :300], X[:, 300:500], X[:, 700:1400]), axis=1)\n",
    "    elif num == 27:\n",
    "        dict_mod = {0:\"T1\", 1:\"T2\", 3:\"DWI\", 4:\"DWIC\"}\n",
    "        list_mod = [1,1,0,1,1]\n",
    "        X_modality = np.concatenate((X[:, :300], X[:, 300:500], X[:, 700:]), axis=1)\n",
    "    elif num == 28:\n",
    "        dict_mod = {0:\"T1\", 1:\"T2\", 2:\"FLAIR\"}\n",
    "        list_mod = [1,1,1,0,0]\n",
    "        X_modality = np.concatenate((X[:, :300], X[:, 300:500], X[:, 500:700]), axis=1)\n",
    "    elif num == 29:\n",
    "        dict_mod = {0:\"T1\", 1:\"T2\", 2:\"FLAIR\", 4:\"DWIC\"}\n",
    "        list_mod = [1,1,1,0,1]\n",
    "        X_modality = np.concatenate((X[:, :300], X[:, 300:500], X[:, 500:700], X[:, 1400:]), axis=1)\n",
    "    elif num == 30:\n",
    "        dict_mod = {0:\"T1\", 1:\"T2\", 2:\"FLAIR\", 3:\"DWI\"}\n",
    "        list_mod = [1,1,1,1,0]\n",
    "        X_modality = np.concatenate((X[:, :300], X[:, 300:500], X[:, 500:700], X[:, 700:1400]), axis=1)\n",
    "    elif num == 31:\n",
    "        dict_mod = {0:\"T1\", 1:\"T2\", 2:\"FLAIR\", 3:\"DWI\", 4:\"DWIC\"}\n",
    "        list_mod = [1,1,1,1,1]\n",
    "        X_modality = np.concatenate((X[:, :300], X[:, 300:500], X[:, 500:700], X[:, 700:]), axis=1)\n",
    "    else:\n",
    "        raise ValueError(f\"num should be betwen 1 and 31, got {num}\")\n",
    "\n",
    "    return X_modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(root: str, node_num: str, j: int):\n",
    "\n",
    "    train_path = os.path.join(root, 'Node_'+node_num, 'Aug_Train_Data', 'ALL_Patients')  \n",
    "    x_file = f\"X_train_aug\"\n",
    "    y_file = f\"Y_train_aug\"\n",
    "    x_mat_name = \"X_aug_train\"\n",
    "    y_mat_name = \"Y_aug_train\"  \n",
    "\n",
    "    raw_path_x = os.path.join(train_path, f\"{x_file}.mat\")\n",
    "    raw_path_y = os.path.join(train_path, f\"{y_file}.mat\")\n",
    "\n",
    "    # Load the data from .mat files\n",
    "    X_mat_l = loadmat(raw_path_x)\n",
    "    X_mat = X_mat_l[x_mat_name]\n",
    "\n",
    "    X_mat_modality = get_modality(j, X_mat) # get X for the modality\n",
    "\n",
    "    Y_mat_l = loadmat(raw_path_y)\n",
    "    Y_mat = Y_mat_l[y_mat_name]\n",
    "    Y_mat = Y_mat.reshape(Y_mat.shape[1],)\n",
    "\n",
    "    return X_mat_modality, Y_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(root: str, node_num: str, j: int):\n",
    "\n",
    "    val_path = os.path.join(root, 'Node_'+node_num, 'Orig_Val_Data', 'ALL_Patients')  \n",
    "    x_file = f\"X_valid_orig\"\n",
    "    y_file = f\"Y_valid_orig\"\n",
    "    x_mat_name = \"X_orig_valid\"\n",
    "    y_mat_name = \"Y_orig_valid\"  \n",
    "\n",
    "    raw_path_x = os.path.join(val_path, f\"{x_file}.mat\")\n",
    "    raw_path_y = os.path.join(val_path, f\"{y_file}.mat\")\n",
    "\n",
    "    # Load the data from .mat files\n",
    "    X_mat_l = loadmat(raw_path_x)\n",
    "    X_mat = X_mat_l[x_mat_name]\n",
    "\n",
    "    X_mat_modality = get_modality(j, X_mat) # get X for the modality\n",
    "\n",
    "    Y_mat_l = loadmat(raw_path_y)\n",
    "    Y_mat = Y_mat_l[y_mat_name]\n",
    "    Y_mat = Y_mat.reshape(Y_mat.shape[1],)\n",
    "\n",
    "    return X_mat_modality, Y_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose model\n",
    "# model = 'MLP'\n",
    "model = 'RF'\n",
    "# model = 'XGB'\n",
    "# model = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop to run the baseline models over all the nodes (for all 5 trials)\n",
    "\n",
    "node_numbers_with_smote = get_list_of_node_nums()\n",
    "\n",
    "for node_num in node_numbers_with_smote:\n",
    "    \n",
    "    print(f'Node num: {node_num}')\n",
    "\n",
    "    num_trials = 5\n",
    "    \n",
    "    # Create empty lists to store results for bal_accuracy\n",
    "    val_bal_acc_list = [[] for _ in range(num_trials)]\n",
    "\n",
    "    # Train and test ALL modality combinations for ALL trials\n",
    "    for j in range(1,32): \n",
    "        # load the data for the given node and given modality combination\n",
    "        X_train, Y_train = load_train_data(root, node_num, j)\n",
    "        \n",
    "        X_test, Y_test = load_test_data(root, node_num, j)\n",
    "\n",
    "        # Define the model\n",
    "        if model == 'MLP':\n",
    "            clf = MLP(hidden_layer_sizes=(256,), learning_rate_init=0.01, random_state=None, max_iter=1000, early_stopping=False)\n",
    "        elif model == 'RF':\n",
    "            clf = RF(n_estimators=100, random_state=None,)\n",
    "        elif model == 'XGB':\n",
    "            clf = xgb(objective='binary:logistic',max_depth = 5,n_estimators = 10, random_state=None) # This is used\n",
    "            # clf = xgb(objective='binary:logistic', n_estimators = 100, random_state=None) # with _1.xlsx extension (NOT Used)\n",
    "        elif model == 'SVM':\n",
    "            clf = SVM(C=1.0, kernel='rbf', max_iter=-1, random_state=None)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Unknown Model.\")\n",
    "\n",
    "        # Run 5 trials for each node\n",
    "        for i in range(num_trials):\n",
    "            print(f'Training Trial {i+1} of Node number {node_num}')\n",
    "\n",
    "            # Train the model\n",
    "            clf.fit(X_train, Y_train)\n",
    "\n",
    "            # Test the model\n",
    "            print(f'Evaluating Trial {i+1} of Node number: {node_num}')\n",
    "            y_true = Y_test\n",
    "            y_pred = clf.predict(X_test)\n",
    "\n",
    "            # Evaluate Trained Model with evaluation metrics\n",
    "            bal_acc = calculate_metrics(y_pred, y_true)  \n",
    "            print(f\"Balanced Accuracy: {bal_acc}\")\n",
    "\n",
    "            val_bal_acc_list[i].append(bal_acc) \n",
    "\n",
    "        # Save the results in a dataframe\n",
    "        # Combine data\n",
    "        row_data_val = [node_num] + [val_bal_acc_list[j][0] for j in range(num_trials)]\n",
    "\n",
    "        # Create a DataFrame\n",
    "        headers_val = ['Node #', 'Val_Bal_Acc_1', 'Val_Bal_Acc_2', 'Val_Bal_Acc_3', 'Val_Bal_Acc_4', 'Val_Bal_Acc_5']\n",
    "\n",
    "        df_val = pd.DataFrame([row_data_val], columns=headers_val)\n",
    "\n",
    "        # Saving to Excel\n",
    "        path = \"/home/neil/Lab_work/Jeong_Lab_Multi_Modal_MRI/Right_Hemis/Part_2/\"\n",
    "        # path = \"/home/neil/Lab_work/Jeong_Lab_Multi_Modal_MRI/Left_Hemis/Part_2/\"  \n",
    "        save_path = os.path.join(path, \"Node_\"+str(node_num), \"Baseline_Results\", \"Modality Combinations\")\n",
    "\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "\n",
    "        # filename_val = model + \"_results_val.xlsx\"\n",
    "        filename_val = model + \"_results_val_T1.xlsx\"\n",
    "        save_filepath_val = os.path.join(save_path, filename_val)\n",
    "\n",
    "        df_val.to_excel(save_filepath_val, index=False, sheet_name='Sheet1')\n",
    "\n",
    "    print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop to run the baseline models over all the nodes (for all 5 trials)\n",
    "\n",
    "node_numbers_with_smote = get_list_of_node_nums()\n",
    "\n",
    "for node_num in node_numbers_with_smote:\n",
    "    \n",
    "    print(f'Node num: {node_num}')\n",
    "\n",
    "    num_trials = 5\n",
    "    \n",
    "    # Create empty lists to store results for bal_accuracy\n",
    "    val_bal_acc_list = [[] for _ in range(num_trials)]\n",
    "\n",
    "    # load the data for the given node\n",
    "    X_train, Y_train = load_train_data(root, node_num)\n",
    "    \n",
    "    X_test, Y_test = load_test_data(root, node_num)\n",
    "\n",
    "    # Define the model\n",
    "    if model == 'MLP':\n",
    "        clf = MLP(hidden_layer_sizes=(256,), learning_rate_init=0.01, random_state=None, max_iter=1000, early_stopping=False)\n",
    "    elif model == 'RF':\n",
    "        clf = RF(n_estimators=100, random_state=None,)\n",
    "    elif model == 'XGB':\n",
    "        clf = xgb(objective='binary:logistic',max_depth = 5,n_estimators = 10, random_state=None) # This is used\n",
    "        # clf = xgb(objective='binary:logistic', n_estimators = 100, random_state=None) # with _1.xlsx extension (NOT Used)\n",
    "    elif model == 'SVM':\n",
    "        clf = SVM(C=1.0, kernel='rbf', max_iter=-1, random_state=None)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Unknown Model.\")\n",
    "\n",
    "    # Run 5 trials for each node\n",
    "    for i in range(num_trials):\n",
    "        print(f'Training Trial {i+1} of Node number {node_num}')\n",
    "\n",
    "        # Train the model\n",
    "        clf.fit(X_train, Y_train)\n",
    "\n",
    "        # Test the model\n",
    "        print(f'Evaluating Trial {i+1} of Node number: {node_num}')\n",
    "        y_true = Y_test\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        # Evaluate Trained Model with evaluation metrics\n",
    "        bal_acc = calculate_metrics(y_pred, y_true)  \n",
    "        print(f\"Balanced Accuracy: {bal_acc}\")\n",
    "\n",
    "        val_bal_acc_list[i].append(bal_acc) \n",
    "\n",
    "    # Save the results in a dataframe\n",
    "    # Combine data\n",
    "    row_data_val = [node_num] + [val_bal_acc_list[j][0] for j in range(num_trials)]\n",
    "\n",
    "    # Create a DataFrame\n",
    "    headers_val = ['Node #', 'Val_Bal_Acc_1', 'Val_Bal_Acc_2', 'Val_Bal_Acc_3', 'Val_Bal_Acc_4', 'Val_Bal_Acc_5']\n",
    "\n",
    "    df_val = pd.DataFrame([row_data_val], columns=headers_val)\n",
    "\n",
    "    # Saving to Excel\n",
    "    path = \"/home/neil/Lab_work/Jeong_Lab_Multi_Modal_MRI/Right_Hemis/Part_2/\"\n",
    "    # path = \"/home/neil/Lab_work/Jeong_Lab_Multi_Modal_MRI/Left_Hemis/Part_2/\"  \n",
    "    save_path = os.path.join(path, \"Node_\"+str(node_num), \"Baseline_Results\", \"Modality Combinations\")\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    # filename_val = model + \"_results_val.xlsx\"\n",
    "    filename_val = model + \"_results_val_T1.xlsx\"\n",
    "    save_filepath_val = os.path.join(save_path, filename_val)\n",
    "\n",
    "    df_val.to_excel(save_filepath_val, index=False, sheet_name='Sheet1')\n",
    "\n",
    "    print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all node results into one dataframe\n",
    "\n",
    "# Define the paths of your Excel files\n",
    "base_path = \"/home/neil/Lab_work/Jeong_Lab_Multi_Modal_MRI/Right_Hemis/Part_2/\"\n",
    "# base_path = \"/home/neil/Lab_work/Jeong_Lab_Multi_Modal_MRI/Left_Hemis/Part_2/\"  \n",
    "\n",
    "# For FULL modality Only\n",
    "node_nums = get_list_of_node_nums()\n",
    "\n",
    "file_paths_val = []\n",
    "\n",
    "for node_num in node_nums:\n",
    "    file_path_val = os.path.join(base_path, \"Node_\"+node_num, \"Baseline_Results\", model + \"_results_val.xlsx\") # For FULL modality Only\n",
    "    file_paths_val.append(file_path_val)\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "combined_df_val = pd.DataFrame()\n",
    "\n",
    "# Loop through the files and stack the rows\n",
    "for path in file_paths_val:\n",
    "    # Load the Excel file\n",
    "    df = pd.read_excel(path)  \n",
    "\n",
    "    # Stack the rows\n",
    "    combined_df_val = pd.concat([combined_df_val, df], axis=0) # For FULL modality Only\n",
    "\n",
    "# Reset the index to avoid duplicate row indices\n",
    "combined_df_val = combined_df_val.reset_index(drop=True)\n",
    "\n",
    "# Save the combined DataFrame to a new Excel file\n",
    "combined_df_val.to_excel(model+'_RightHemis_val_FULL_modality_Only.xlsx', index=False)\n",
    "# combined_df_val.to_excel(model+'_LeftHemis_val_FULL_modality_Only.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magms_ez",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
